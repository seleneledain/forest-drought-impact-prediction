{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "489080c3-5701-4128-8f2b-882e54cd1f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dccstor/cimf/drought_impact/drought/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50891e99-f0b3-4ba8-ae3d-61ab31f2935a",
   "metadata": {},
   "source": [
    "# Combine norm stats\n",
    "- The stattistcis of the training set might have been computed in several times\n",
    "- Combine them all here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad6e143-58c8-4221-8738-8d9d01afbb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_path = 'pixel_data/nofilter/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f281156-ba48-423f-a56b-fd63f43d2805",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_subset = [os.path.join(stats_path, stat) for stat in os.listdir(stats_path) if stat.endswith('.pt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2cd957ad-b315-4dcd-a286-135ded4d9041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_data/nofilter/train/norm_stats.pt']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "593190af-c805-4301-bb47-1e1ebf7cfe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_data/nofilter/train/norm_stats.pt\n"
     ]
    }
   ],
   "source": [
    "# Load, stack, compute new stats, save\n",
    "all_bands_min = []\n",
    "all_bands_max = []\n",
    "\n",
    "for stat in stat_subset:\n",
    "    print(stat)\n",
    "    [all_bands_min_new, all_bands_max_new] = th.load(stat)\n",
    "    all_bands_min.append(all_bands_min_new)\n",
    "    all_bands_max.append(all_bands_max_new)\n",
    "    \n",
    "new_bands_min = np.stack(all_bands_min).min(axis=0)\n",
    "new_bands_max = np.stack(all_bands_max).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e65c30cf-d86f-4887-9a44-9d8a3126e755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bands_max[0][14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ebb034d-b947-4a8b-8c8b-2fc55e7cfbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "th.save([list(new_bands_min), list(new_bands_max)], stats_path+'/norm_stats.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24205587-be9b-436a-9530-d2d1a6b13cb4",
   "metadata": {},
   "source": [
    "# Check number of files created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a050ed-1979-453e-8ca3-d92ccbd4dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = 'pixel_data/nofilter/test_vaud/x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c43e23-d62e-496f-9f8a-b8e5969e31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [os.path.join(path_data, f) for f in os.listdir(path_data) if f.endswith('.pt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600689af-6493-4b6d-8f28-ed4b21c73880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_key(file):\n",
    "    return int(re.findall(r\"\\d+\", file)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49fe301f-2c66-46a8-b029-8e3ab9cd6453",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_list = sorted(data_list, key=sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a75f6c5b-7df1-4f47-a17b-dd872b0a5e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ordered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5524d63e-3015-4816-a814-f6fa56bd8970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pixel_data/nofilter/test_vaud/x/data_cube_5999.pt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "11daa8f5-fa71-4978-a80a-3b1a7333817e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "if 'pixel_data/nofilter/train/x/data_cube_1000.pt' in ordered_list:\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fa425ed2-d5ed-4ee2-b41b-996182441e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pixel_data/arch_exp/val/x/data_cube_4999.pt'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e93923e4-5a8d-4dd9-a7b3-de9ed15802d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_path = 'pixel_data/arch_exp/train/persistance_r2.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0911bb58-a01c-4fbf-abdf-fa4fee18df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = th.load(stats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "477f5dcd-e1f6-4f75-81a6-90e60768f15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011043884350258932"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3447e5f9-a8bc-4a5b-b782-64f7fff7f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = th.load(stats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a7d6230-1e79-4080-bc3f-bee92f7f91fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0603094978121083"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ff7171-a2ec-4b36-a334-62e2c7cb28e1",
   "metadata": {},
   "source": [
    "# Get cloud free data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd60208b-f28d-4b9a-a394-1cd671e27aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5953d3c-6e94-40d9-9a09-082513002f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils.utils_pixel import *\n",
    "\n",
    "exp = 'nofilter'\n",
    "batch = 0\n",
    "batch_size = 40 \n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d7fd30-81db-44de-a154-45594b207196",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = 'pixel_data/nofilter/train/x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "905845c7-6259-48e2-bdbb-afffc9f135cd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batch\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m50\u001b[39m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mat batch\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch)\n\u001b[0;32m----> 6\u001b[0m img, label \u001b[38;5;241m=\u001b[39m \u001b[43mload_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_nbr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpixel_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnofilter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_timesteps_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m cp_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m14\u001b[39m\n\u001b[1;32m      9\u001b[0m cp_data \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mcat([img[:,:,cp_idx,:,:] ,label[:,:,cp_idx,:,:]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/dccstor/cimf/drought_impact/pixel_based/utils/utils_pixel.py:716\u001b[0m, in \u001b[0;36mload_batch\u001b[0;34m(batch_size, batch_nbr, sample_type, split, exp, n_timesteps_out)\u001b[0m\n\u001b[1;32m    713\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_nbr\u001b[38;5;241m*\u001b[39mbatch_size, (batch_nbr\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mbatch_size):\n\u001b[0;32m--> 716\u001b[0m     x,y \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_cube\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m     x_batch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    718\u001b[0m     y_batch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y[:,:n_timesteps_out, :]\n",
      "File \u001b[0;32m/dccstor/cimf/drought_impact/pixel_based/utils/utils_pixel.py:697\u001b[0m, in \u001b[0;36mload_data_cube\u001b[0;34m(sample_type, split, idx, exp)\u001b[0m\n\u001b[1;32m    694\u001b[0m datacube_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/y/data_cube_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;66;03m#load tensors\u001b[39;00m\n\u001b[0;32m--> 697\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatacube_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m y \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mload(datacube_y)\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x,y\n",
      "File \u001b[0;32m~/.conda/envs/drought2/lib/python3.8/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.conda/envs/drought2/lib/python3.8/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.conda/envs/drought2/lib/python3.8/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cloud_free_samples = list()\n",
    "\n",
    "for batch in range(1000):\n",
    "    if not batch%50:\n",
    "        print(\"at batch\", batch)\n",
    "    img, label = load_batch(batch_size = batch_size, batch_nbr = batch, sample_type = 'pixel_data', split='train', exp='nofilter', n_timesteps_out=1)\n",
    "\n",
    "    cp_idx = 14\n",
    "    cp_data = th.cat([img[:,:,cp_idx,:,:] ,label[:,:,cp_idx,:,:]], axis=1)\n",
    "    \n",
    "    # Check if sample(s) in cp_data  are fully cloud free\n",
    "    for sample_id in range(cp_data.size(0)):\n",
    "        sample = cp_data[sample_id,:,:,:]\n",
    "        condition = th.all(sample < 0.5)\n",
    "        if condition:\n",
    "            cloud_free_samples.append(batch*40+sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "004beecb-4169-4812-9352-d52a5f91f2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch 0\n",
      "at batch 50\n"
     ]
    }
   ],
   "source": [
    "# Check where the first and last didnt have to get dropped\n",
    "\n",
    "exp = 'nofilter'\n",
    "batch = 0\n",
    "batch_size = 40 \n",
    "epoch = 0\n",
    "split = 'val'\n",
    "\n",
    "path_data = f'pixel_data/{exp}/{split}/x'\n",
    "\n",
    "cloud_free_samples = list()\n",
    "\n",
    "for batch in range(100):\n",
    "    if not batch%50:\n",
    "        print(\"at batch\", batch)\n",
    "    img, label = load_batch(batch_size = batch_size, batch_nbr = batch, sample_type = 'pixel_data', split=split, exp=exp, n_timesteps_out=1)\n",
    "\n",
    "    cp_idx = 14\n",
    "    cp_data = th.cat([img[:,:,cp_idx,:,:] ,label[:,:,cp_idx,:,:]], axis=1)\n",
    "    \n",
    "    # Check if start/end got replaced\n",
    "    for sample_id in range(cp_data.size(0)):\n",
    "        first = cp_data[sample_id,0,:,:]\n",
    "        last = cp_data[sample_id,-1,:,:]\n",
    "        if first==0 and last==0:\n",
    "            cloud_free_samples.append(batch*40+sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fde2149-b40c-4377-93b0-4f88ef68e60d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at batch 0\n",
      "at batch 50\n"
     ]
    }
   ],
   "source": [
    "# Check where the last point (label) didnt have to get dropped\n",
    "import torch as th\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.utils_pixel import *\n",
    "\n",
    "exp = 'nofilter'\n",
    "batch = 0\n",
    "batch_size = 40 \n",
    "epoch = 0\n",
    "split = 'test'\n",
    "\n",
    "path_data = f'pixel_data/{exp}/{split}/x'\n",
    "\n",
    "cloud_free_samples = list()\n",
    "\n",
    "cp_idx = 14\n",
    "b2_idx = 6\n",
    "    \n",
    "for batch in range(100):\n",
    "    if not batch%50:\n",
    "        print(\"at batch\", batch)\n",
    "    img, label = load_batch(batch_size = batch_size, batch_nbr = batch, sample_type = 'pixel_data', split=split, exp=exp, n_timesteps_out=1)\n",
    "\n",
    "        \n",
    "    for sample_id in range(cp_data.size(0)):\n",
    "        cp_data = th.cat([img[sample_id,:,cp_idx,:,:] ,label[sample_id,:,cp_idx,:,:]], axis=0)\n",
    "        b2_data = th.cat([img[sample_id,:,b2_idx,:,:] ,label[sample_id,:,b2_idx,:,:]], axis=0)\n",
    "        \n",
    "        # Check if start/end got replaced\n",
    "        to_rep = ((b2_data>0.1) & (cp_data>0.01))\n",
    "        if to_rep.sum() < 9: \n",
    "            to_rep = ((b2_data>0.15) & (cp_data>0.01))\n",
    "        \n",
    "        if to_rep[-1]:\n",
    "            cloud_free_samples.append(batch*40+sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce65db9-8072-422e-ac8c-302cf8f51620",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cloud_free_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a9125-7a6a-4dfe-87c8-78056096c2df",
   "metadata": {},
   "source": [
    "# Combine called samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8f01d24-fb99-4566-ad90-d4e7635bb340",
   "metadata": {},
   "outputs": [],
   "source": [
    "called_path = 'pixel_data/nofilter/train'\n",
    "called_subset = [os.path.join(called_path, called) for called in os.listdir(called_path) if 'called_samples' in called]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7147c95-3819-424b-973d-2314a02932d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p1_1000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p1_0.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p1_6000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p1_7000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p2_0.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p1_3000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p1_8000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p1_2000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p2_2000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p2_7000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p1_0.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p2_7000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p1_9000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p2_1000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p2_4000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p2_9000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p1_6000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p1_8000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p2_2000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p1_9000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p2_8000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p1_4000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p2_6000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p1_4000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p2_4000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p1_1000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p2_0.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p1_2000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p2_5000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p1_5000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p1_5000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p1_7000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p2_5000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p1_3000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p2_1000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p2_6000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p2_3000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2019_nofilter_p2_3000.pt',\n",
       " 'pixel_data/nofilter/train/called_samples_jura_config_rec_2018_nofilter_p2_8000.pt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "called_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3937280-5fa6-4798-932f-17661265e319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(called_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bc320a5-5f5a-42e0-9c04-98a58758c732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, stack, compute new stats, save\n",
    "list_called = list()\n",
    "\n",
    "for called in called_subset:\n",
    "    list_subset = th.load(called)\n",
    "    list_called += list_subset\n",
    "    \n",
    "# Careful, index for timeseries is different depedning on year and p1 vs p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c89fc556-7b54-4cf9-8109-954c64e2f665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if same pixel called multiple times\n",
    "list_pixs = [x[0][1:] for x in list_called]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fc6bd31-297c-41fc-9d40-81fd18400054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_pixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9ef82e1-4920-4245-80bc-b0a7849742e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list_pixs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ec68e-c8d2-40b5-b04a-4148b01908f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drought",
   "language": "python",
   "name": "drought"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
